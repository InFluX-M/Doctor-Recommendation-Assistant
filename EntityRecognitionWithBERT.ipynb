{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d521e-c6c0-4979-b855-b2d1f367a091",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d7d521e-c6c0-4979-b855-b2d1f367a091",
    "outputId": "8a00bb9f-55f7-4b15-8c09-254c1d57873f"
   },
   "outputs": [],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46785b6",
   "metadata": {
    "id": "f46785b6"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4731ac97-9958-4832-a36e-85f1d7028d34",
   "metadata": {
    "id": "4731ac97-9958-4832-a36e-85f1d7028d34"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForTokenClassification, PreTrainedTokenizer, PreTrainedModel\n",
    "import mlflow\n",
    "from seqeval.metrics import precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import TokenClassifierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a09b1f3-696a-49ca-999e-14d6d2f8121a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a09b1f3-696a-49ca-999e-14d6d2f8121a",
    "outputId": "362ad0a2-a103-40a5-da6b-669a749bcc83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ebd497d-217d-4784-97ed-6e93c1beb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/form_gpt_generate_with_dif_cities.csv\"\n",
    "ANALYSIS = False\n",
    "PRETRAINED_MODEL = 'HooshvareLab/bert-fa-base-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2231f1",
   "metadata": {
    "id": "cb2231f1"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24afd3a7-9e44-4042-af0e-8a3620ac19f9",
   "metadata": {
    "id": "24afd3a7-9e44-4042-af0e-8a3620ac19f9"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95d8b23e-8886-4c31-bd56-dda17dbfa72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>سلام . یک فوق تخصص پوست خانوم واسه هفته آینده ...</td>\n",
       "      <td>O,O,O,B-srt,I-srt,B-spy,B-gnd,O,B-apt,I-apt,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>سلام . یک فوق تخصص پوست مرد شیرازی برای بلفارو...</td>\n",
       "      <td>O,O,O,B-srt,I-srt,B-spy,B-gnd,B-cty,O,B-cnd,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>سلام یک متخصص جراح ترجیحا آقا توی شیراز بلوار ...</td>\n",
       "      <td>O,O,B-srt,B-spy,O,B-gnd,O,B-cty,B-nhd,I-nhd,I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>سلام یک متخصص گوش و حلق و بینی برای اختلالات گ...</td>\n",
       "      <td>O,O,B-srt,B-spy,O,B-spy,O,B-spy,O,B-cnd,I-cnd,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>سلام من یک دندون پزشک فوق تخصص برای کج بودن دن...</td>\n",
       "      <td>O,O,O,B-spy,I-spy,B-srt,I-srt,O,B-cnd,I-cnd,I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>آیا می‌توانید یک متخصص عفونی برای همسرم در منط...</td>\n",
       "      <td>O,O,O,B-srt,B-spy,O,O,O,O,B-cty,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>نیاز به یک پزشک مشهدی ارتوپد برای شوهرم دارم ک...</td>\n",
       "      <td>O,O,O,O,B-cty,B-spy,O,O,O,O,O,O,O,B-vtp,I-vtp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>آیا در یزد یک پزشک متخصص اطفال میشناسید که بتو...</td>\n",
       "      <td>O,O,B-cty,O,O,B-srt,B-spy,O,O,O,O,O,B-cnd,I-cn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>برای درمان پوکی استخوان پدرم به دنبال یک متخصص...</td>\n",
       "      <td>O,O,B-cnd,I-cnd,O,O,O,O,B-srt,B-spy,O,O,B-cty,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>دنبال یک متخصص گوش و حلق و بینی برای خانومم در...</td>\n",
       "      <td>O,O,B-srt,B-spy,O,B-spy,O,B-spy,O,O,O,O,B-nhd,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  \\\n",
       "0.0  سلام . یک فوق تخصص پوست خانوم واسه هفته آینده ...   \n",
       "1.0  سلام . یک فوق تخصص پوست مرد شیرازی برای بلفارو...   \n",
       "2.0  سلام یک متخصص جراح ترجیحا آقا توی شیراز بلوار ...   \n",
       "3.0  سلام یک متخصص گوش و حلق و بینی برای اختلالات گ...   \n",
       "4.0  سلام من یک دندون پزشک فوق تخصص برای کج بودن دن...   \n",
       "..                                                 ...   \n",
       "NaN  آیا می‌توانید یک متخصص عفونی برای همسرم در منط...   \n",
       "NaN  نیاز به یک پزشک مشهدی ارتوپد برای شوهرم دارم ک...   \n",
       "NaN  آیا در یزد یک پزشک متخصص اطفال میشناسید که بتو...   \n",
       "NaN  برای درمان پوکی استخوان پدرم به دنبال یک متخصص...   \n",
       "NaN  دنبال یک متخصص گوش و حلق و بینی برای خانومم در...   \n",
       "\n",
       "                                                 label  \n",
       "0.0  O,O,O,B-srt,I-srt,B-spy,B-gnd,O,B-apt,I-apt,O,...  \n",
       "1.0  O,O,O,B-srt,I-srt,B-spy,B-gnd,B-cty,O,B-cnd,O,...  \n",
       "2.0  O,O,B-srt,B-spy,O,B-gnd,O,B-cty,B-nhd,I-nhd,I-...  \n",
       "3.0  O,O,B-srt,B-spy,O,B-spy,O,B-spy,O,B-cnd,I-cnd,...  \n",
       "4.0  O,O,O,B-spy,I-spy,B-srt,I-srt,O,B-cnd,I-cnd,I-...  \n",
       "..                                                 ...  \n",
       "NaN  O,O,O,B-srt,B-spy,O,O,O,O,B-cty,O,O,O,O,O,O,O,...  \n",
       "NaN  O,O,O,O,B-cty,B-spy,O,O,O,O,O,O,O,B-vtp,I-vtp,...  \n",
       "NaN  O,O,B-cty,O,O,B-srt,B-spy,O,O,O,O,O,B-cnd,I-cn...  \n",
       "NaN  O,O,B-cnd,I-cnd,O,O,O,O,B-srt,B-spy,O,O,B-cty,...  \n",
       "NaN  O,O,B-srt,B-spy,O,B-spy,O,B-spy,O,O,O,O,B-nhd,...  \n",
       "\n",
       "[265 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c81406d1-9ca2-4256-a632-303fd51aeb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-apt',\n",
       " 'B-cnd',\n",
       " 'B-cty',\n",
       " 'B-gnd',\n",
       " 'B-inc',\n",
       " 'B-nhd',\n",
       " 'B-spy',\n",
       " 'B-srt',\n",
       " 'B-trt',\n",
       " 'B-vtp',\n",
       " 'B-wtt',\n",
       " 'I-apt',\n",
       " 'I-cnd',\n",
       " 'I-cty',\n",
       " 'I-inc',\n",
       " 'I-nhd',\n",
       " 'I-spy',\n",
       " 'I-srt',\n",
       " 'I-trt',\n",
       " 'I-vtp',\n",
       " 'I-wtt',\n",
       " 'O']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all unique BIO tags used in the dataset\n",
    "unique_bio_tags = set(tag for bio_tag in data['label'] for tag in bio_tag.split(','))\n",
    "\n",
    "# Convert to a sorted list\n",
    "unique_bio_tags_list = sorted(unique_bio_tags)\n",
    "\n",
    "unique_bio_tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "XPP2pstN18Et",
   "metadata": {
    "id": "XPP2pstN18Et"
   },
   "outputs": [],
   "source": [
    "# Define the substrings to be replaced and their replacement\n",
    "to_replace = ['I-nhd', 'B-nhd', 'I-wtt', 'B-wtt']\n",
    "replacement = 'O'\n",
    "\n",
    "# Use the replace method with regex to replace the values in the column\n",
    "data['label'] = data['label'].str.replace(r'\\b(I-wtt|B-wtt)\\b', 'O', regex=True)\n",
    "data['label'] = data['label'].str.replace(r'\\b(I-nhd)\\b', 'I-loc', regex=True)\n",
    "data['label'] = data['label'].str.replace(r'\\b(B-nhd)\\b', 'B-loc', regex=True)\n",
    "data['label'] = data['label'].str.replace(r'\\b(I-cty)\\b', 'I-loc', regex=True)\n",
    "data['label'] = data['label'].str.replace(r'\\b(B-cty)\\b', 'B-loc', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e29718e-695b-437a-bf5c-662f998aaff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-apt',\n",
       " 'B-cnd',\n",
       " 'B-gnd',\n",
       " 'B-inc',\n",
       " 'B-loc',\n",
       " 'B-spy',\n",
       " 'B-srt',\n",
       " 'B-trt',\n",
       " 'B-vtp',\n",
       " 'I-apt',\n",
       " 'I-cnd',\n",
       " 'I-inc',\n",
       " 'I-loc',\n",
       " 'I-spy',\n",
       " 'I-srt',\n",
       " 'I-trt',\n",
       " 'I-vtp',\n",
       " 'O']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all unique BIO tags used in the dataset\n",
    "unique_bio_tags = set(tag for bio_tag in data['label'] for tag in bio_tag.split(','))\n",
    "\n",
    "# Convert to a sorted list\n",
    "unique_bio_tags_list = sorted(unique_bio_tags)\n",
    "\n",
    "unique_bio_tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "VhnI6ld9NArM",
   "metadata": {
    "id": "VhnI6ld9NArM"
   },
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    'O': 0,\n",
    "    'B-apt': 1,\n",
    "    'I-apt': 2,\n",
    "    'B-loc': 3,\n",
    "    'I-loc': 4,\n",
    "    'B-cnd': 5,\n",
    "    'I-cnd': 6,\n",
    "    'B-gnd': 7,\n",
    "    'I-gnd': 8,\n",
    "    'B-inc': 9,\n",
    "    'I-inc': 10,\n",
    "    'B-srt': 11,\n",
    "    'I-srt': 12,\n",
    "    'B-spy': 13,\n",
    "    'I-spy': 14,\n",
    "    'B-trt': 15,\n",
    "    'I-trt': 16,\n",
    "    'B-vtp': 17,\n",
    "    'I-vtp': 18\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "jnQgjpdF8DIV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnQgjpdF8DIV",
    "outputId": "d9101eb3-fbec-45c2-baa8-06d0074288f2"
   },
   "outputs": [],
   "source": [
    "if ANALYSIS:\n",
    "    datas = []\n",
    "    for i, d in data.iterrows():\n",
    "      sen = d['sentence'].split()\n",
    "      lab = d['label'].split(',')\n",
    "      print(len(sen), len(lab))\n",
    "      for j in range(max(len(sen), len(lab))):\n",
    "        print(sen[j], lab[j])\n",
    "      print('---------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bbc397",
   "metadata": {
    "id": "37bbc397"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49a951c1-e578-4f20-8f43-067e775762e5",
   "metadata": {
    "id": "49a951c1-e578-4f20-8f43-067e775762e5"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93d279f7-347b-4624-97e0-06d35688268c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/nlu/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dee005",
   "metadata": {
    "id": "10dee005"
   },
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40d77460-803e-4539-a840-70c1026e6ccf",
   "metadata": {
    "id": "40d77460-803e-4539-a840-70c1026e6ccf"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence: str, text_labels: str, tokenizer: PreTrainedTokenizer) -> tuple[list[str], list[str]]:\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75bbdf06-635f-48b9-8d6a-84bc06cad836",
   "metadata": {
    "id": "75bbdf06-635f-48b9-8d6a-84bc06cad836"
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, tokenizer: PreTrainedTokenizer, max_len: int) -> None:\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index :int):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.sentence[index]\n",
    "        word_labels = self.data.label[index]\n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "\n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "\n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "\n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d19af0c",
   "metadata": {
    "id": "5d19af0c"
   },
   "source": [
    "## Split into Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bf055f2-291b-40b4-8e61-06fb051f8602",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bf055f2-291b-40b4-8e61-06fb051f8602",
    "outputId": "fb2de939-a253-44f6-d0f9-4e5999a5de19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (265, 2)\n",
      "TRAIN Dataset: (199, 2)\n",
      "TEST Dataset: (61, 2)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 0.8\n",
    "train_dataset = data.sample(frac=TRAIN_SIZE, random_state=15)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb59597c-76a1-4b72-a1ff-599655c27da3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb59597c-76a1-4b72-a1ff-599655c27da3",
    "outputId": "b6f49859-076b-4603-c73a-bf374a2bc6f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([    2,  4285,  1012,  2829,  4692,  9084,  4903,  2999,  9921,  2831,\n",
       "         98401, 47588,  1379, 10850,  3080,  3510,  2860,  2800,  3757, 44118,\n",
       "          5921, 12139,  1379,  4197,  3878,  1379, 12017, 12139,  1012,  1379,\n",
       "          3671,  5032,  4202,  4663, 12139,  1379,  3400,  3973,  3551,  3130,\n",
       "          2861,  6624,  6878,  6041,  2015,  1012,     4,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'targets': tensor([ 0,  0,  0,  0, 11, 12, 13,  7,  3,  0,  5,  5,  0,  5,  6,  0,  0,  0,\n",
       "          0,  3,  4,  0,  0, 15, 16,  0, 15,  0,  0,  0,  0,  0,  0,  9,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35e9f58b-549e-41cf-8019-a32cef969cbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "35e9f58b-549e-41cf-8019-a32cef969cbf",
    "outputId": "6d8af2ec-312a-4a60-99ac-1c96ab5d0424"
   },
   "outputs": [],
   "source": [
    "if ANALYSIS:\n",
    "    for i in range(test_dataset.shape[0]):\n",
    "        for token, label in zip(tokenizer.convert_ids_to_tokens(testing_set[i][\"ids\"][:60]), testing_set[i][\"targets\"][:60]):\n",
    "          print('{0:10}  {1}'.format(token, id2label[label.item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61c58c8e-6486-4128-90fc-1fa884dbb37d",
   "metadata": {
    "id": "61c58c8e-6486-4128-90fc-1fa884dbb37d"
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9684ef",
   "metadata": {
    "id": "0b9684ef"
   },
   "source": [
    "# Define and track models with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1c5a730",
   "metadata": {
    "id": "b1c5a730"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "FREAZING_LAYERS = 8\n",
    "NUM_ADDITIONAL_LAYERS_TOP = 2\n",
    "ACTIVATION = \"GELU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec69a91d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec69a91d",
    "outputId": "9bf8d986-44d9-4df5-ac68-dae56ca10e89"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file 'mlflow/mlruns/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/nlu/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py\", line 317, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/envs/nlu/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py\", line 410, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/envs/nlu/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py\", line 1341, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/envs/nlu/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py\", line 1334, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/envs/nlu/lib/python3.12/site-packages/mlflow/utils/file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'mlflow/mlruns/meta.yaml' does not exist.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/user/Desktop/hammasir-project/mlflow/968568366775758109', creation_time=1724758511411, experiment_id='968568366775758109', last_update_time=1724758511411, lifecycle_stage='active', name='NER', tags={}>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"mlflow\")\n",
    "mlflow.set_experiment(\"NER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169509bb",
   "metadata": {
    "id": "169509bb"
   },
   "source": [
    "## Writing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "NPtTq5EXaIGD",
   "metadata": {
    "id": "NPtTq5EXaIGD"
   },
   "outputs": [],
   "source": [
    "class CustomBertForTokenClassification(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_labels, id2label, label2id, num_additional_layers=1, hidden_dim=768):\n",
    "        super(CustomBertForTokenClassification, self).__init__()\n",
    "        self.bert = BertForTokenClassification.from_pretrained(\n",
    "            pretrained_model,\n",
    "            num_labels=num_labels,\n",
    "            id2label=id2label,\n",
    "            label2id=label2id\n",
    "        )\n",
    "\n",
    "        self.num_labels=num_labels\n",
    "\n",
    "        # Additional layers\n",
    "        self.additional_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_dim, hidden_dim) for _ in range(num_additional_layers)\n",
    "        ])\n",
    "\n",
    "        # Activation function\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "        # Final classification layer\n",
    "        self.classifier = nn.Linear(hidden_dim, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        outputs = self.bert.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]  # [batch_size, seq_length, hidden_size]\n",
    "\n",
    "        # Pass through additional layers\n",
    "        for layer in self.additional_layers:\n",
    "            sequence_output = self.activation(layer(sequence_output))\n",
    "\n",
    "        # Pass through the final classification layer\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            active_loss = attention_mask.view(-1) == 1\n",
    "            active_logits = logits.view(-1, logits.size(-1))\n",
    "            active_labels = torch.where(\n",
    "                active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n",
    "            )\n",
    "            loss = loss_fct(active_logits, active_labels)\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f_LXCNBDaOcs",
   "metadata": {
    "id": "f_LXCNBDaOcs"
   },
   "outputs": [],
   "source": [
    "def initialize_model(id2label: dict, label2id: dict, training_set, freeze_layers: int = 0, num_additional_layers: int = 1) -> tuple[nn.Module, torch.Tensor]:\n",
    "    model = CustomBertForTokenClassification(\n",
    "        pretrained_model=PRETRAINED_MODEL,\n",
    "        num_labels=len(id2label),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        num_additional_layers=num_additional_layers\n",
    "    )\n",
    "\n",
    "    # Freeze the first `freeze_layers` transformer layers\n",
    "    for param in model.bert.bert.embeddings.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for i in range(freeze_layers):\n",
    "        for param in model.bert.bert.encoder.layer[i].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    model.to(device)\n",
    "    ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "    mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "    targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "    ids = ids.to(device)\n",
    "    mask = mask.to(device)\n",
    "    targets = targets.to(device)\n",
    "    outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "    initial_loss = outputs[0]\n",
    "    return model, initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4bd72ebb-5449-4f67-bb07-c24423b5fff5",
   "metadata": {
    "id": "4bd72ebb-5449-4f67-bb07-c24423b5fff5"
   },
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(optimizer: torch.optim.Adam, max_norm: int, training_loader: DataLoader, model: PreTrainedModel) -> tuple[PreTrainedModel, float, float]:\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "\n",
    "    for idx, batch in enumerate(training_loader):\n",
    "\n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "\n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "\n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=max_norm\n",
    "        )\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    return model, epoch_loss, tr_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "432c9934-d6d3-453e-a6b9-2152d9cf1956",
   "metadata": {
    "id": "432c9934-d6d3-453e-a6b9-2152d9cf1956"
   },
   "outputs": [],
   "source": [
    "def valid(model: PreTrainedModel, testing_loader: DataLoader, device: str, id2label: dict, label2id: dict) -> tuple[list[str], list[str], float, float]:\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "\n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "\n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "\n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "\n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "\n",
    "    return labels, predictions, eval_loss, eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0027504-f122-4884-a07e-1191ff34ecb7",
   "metadata": {
    "id": "c0027504-f122-4884-a07e-1191ff34ecb7"
   },
   "outputs": [],
   "source": [
    "def predict(sentence: str, model: PreTrainedModel, tokenizer: BertTokenizer, id2label: dict, device: str, details : bool = False) -> str:\n",
    "    inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "    # Move to GPU\n",
    "    ids = inputs[\"input_ids\"].to(device)\n",
    "    mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(ids, mask)\n",
    "    logits = outputs[0]\n",
    "\n",
    "    active_logits = logits.view(-1, model.num_labels)  # shape (batch_size * seq_len, num_labels)\n",
    "\n",
    "    # Get top 5 predictions for each token\n",
    "    top_predictions = torch.topk(active_logits, k=5, dim=1)\n",
    "\n",
    "    top_indices = top_predictions.indices.cpu().numpy()  # shape (batch_size * seq_len, 5)\n",
    "    top_scores = top_predictions.values.cpu().detach().numpy()  # shape (batch_size * seq_len, 5)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "\n",
    "    wp_preds = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token not in ['[CLS]', '[SEP]', '[PAD]']:\n",
    "            preds = [(id2label[idx], score) for idx, score in zip(top_indices[i], top_scores[i])]\n",
    "            wp_preds.append((token, preds))\n",
    "\n",
    "    if details:\n",
    "    # Print word-level predictions\n",
    "      print(\"Word-Level Predictions with Top 5 Labels:\")\n",
    "      for token, preds in wp_preds:\n",
    "          print(f\"Word: {token}\")\n",
    "          for label, score in preds:\n",
    "              print(f\"  Label: {label}, Score: {score:.4f}\")\n",
    "          print()  # New line for readability\n",
    "\n",
    "    # Construct the final sentence with word and top label\n",
    "    final_sentence = []\n",
    "    for token, preds in wp_preds:\n",
    "        best_label = preds[0][0]  # get the label with the highest score\n",
    "        final_sentence.append(f\"{token} ({best_label})\")\n",
    "\n",
    "    # Join tokens (removing \"##\" in wordpieces)\n",
    "    final_str = \" \".join(final_sentence).replace(\" ##\", \"\")\n",
    "\n",
    "    return final_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c97b8b",
   "metadata": {
    "id": "16c97b8b"
   },
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0eb3366-f0e4-416e-a972-29de1c5fbdf5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0eb3366-f0e4-416e-a972-29de1c5fbdf5",
    "outputId": "f4833575-bc23-4eae-eb50-a0ee3e287119"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 2.9542906284332275\n",
      "tr_accuracy =  0.6131057078598996\n",
      "Validation loss per 100 evaluation steps: 1.6958163976669312\n",
      "eval_accuracy =  0.6705833037115977\n",
      "Training loss per 100 training steps: 1.7279322147369385\n",
      "tr_accuracy =  0.6775732326932331\n",
      "Validation loss per 100 evaluation steps: 1.0639467239379883\n",
      "eval_accuracy =  0.670008685181426\n",
      "Training loss per 100 training steps: 1.3504359722137451\n",
      "tr_accuracy =  0.7045153594843753\n",
      "Validation loss per 100 evaluation steps: 0.807121217250824\n",
      "eval_accuracy =  0.7447594937754936\n",
      "Training loss per 100 training steps: 0.8285091519355774\n",
      "tr_accuracy =  0.763402140261997\n",
      "Validation loss per 100 evaluation steps: 0.861348569393158\n",
      "eval_accuracy =  0.796707273203281\n",
      "Training loss per 100 training steps: 0.7084516882896423\n",
      "tr_accuracy =  0.8165329308056415\n",
      "Validation loss per 100 evaluation steps: 0.398968905210495\n",
      "eval_accuracy =  0.8532711634082776\n",
      "Training loss per 100 training steps: 0.6019333600997925\n",
      "tr_accuracy =  0.8706708120054194\n",
      "Validation loss per 100 evaluation steps: 0.5709244608879089\n",
      "eval_accuracy =  0.8896725447711957\n",
      "Training loss per 100 training steps: 0.4681687355041504\n",
      "tr_accuracy =  0.907501797852451\n",
      "Validation loss per 100 evaluation steps: 0.695861279964447\n",
      "eval_accuracy =  0.9222837933884704\n",
      "Training loss per 100 training steps: 0.24464081227779388\n",
      "tr_accuracy =  0.9365685555594598\n",
      "Validation loss per 100 evaluation steps: 0.2701945900917053\n",
      "eval_accuracy =  0.9379901435034381\n",
      "Training loss per 100 training steps: 0.2539426386356354\n",
      "tr_accuracy =  0.9498246779414417\n",
      "Validation loss per 100 evaluation steps: 0.22664974629878998\n",
      "eval_accuracy =  0.9478020283910252\n",
      "Training loss per 100 training steps: 0.25892379879951477\n",
      "tr_accuracy =  0.9642397742004004\n",
      "Validation loss per 100 evaluation steps: 0.21492965519428253\n",
      "eval_accuracy =  0.9519200024561176\n",
      "Training loss per 100 training steps: 0.1542387306690216\n",
      "tr_accuracy =  0.9704289052511479\n",
      "Validation loss per 100 evaluation steps: 0.3328678607940674\n",
      "eval_accuracy =  0.9551922100905537\n",
      "Training loss per 100 training steps: 0.07543642073869705\n",
      "tr_accuracy =  0.9831922949390498\n",
      "Validation loss per 100 evaluation steps: 0.12959063053131104\n",
      "eval_accuracy =  0.9584113400140529\n",
      "Training loss per 100 training steps: 0.05088962987065315\n",
      "tr_accuracy =  0.9866478880998143\n",
      "Validation loss per 100 evaluation steps: 0.0390954464673996\n",
      "eval_accuracy =  0.9642692565395661\n",
      "Training loss per 100 training steps: 0.03702757507562637\n",
      "tr_accuracy =  0.9900493052146385\n",
      "Validation loss per 100 evaluation steps: 0.3833145201206207\n",
      "eval_accuracy =  0.9698432485093972\n",
      "Training loss per 100 training steps: 0.054147593677043915\n",
      "tr_accuracy =  0.9927288108265709\n",
      "Validation loss per 100 evaluation steps: 0.020502176135778427\n",
      "eval_accuracy =  0.9683500647489938\n",
      "Validation loss per 100 evaluation steps: 0.05518493801355362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 09:52:24 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_accuracy =  0.9710348957328973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-apt       0.94      0.94      0.94        36\n",
      "       B-cnd       0.85      0.85      0.85        41\n",
      "       B-gnd       1.00      1.00      1.00        19\n",
      "       B-inc       1.00      1.00      1.00        18\n",
      "       B-loc       0.92      0.94      0.93        78\n",
      "       B-spy       0.97      0.99      0.98        73\n",
      "       B-srt       1.00      0.98      0.99        42\n",
      "       B-trt       0.90      0.96      0.93        54\n",
      "       B-vtp       1.00      1.00      1.00        12\n",
      "       I-apt       1.00      0.89      0.94        27\n",
      "       I-cnd       0.88      0.64      0.74        33\n",
      "       I-inc       0.83      1.00      0.91        10\n",
      "       I-loc       0.91      0.83      0.87        24\n",
      "       I-spy       0.90      0.95      0.93        20\n",
      "       I-srt       1.00      1.00      1.00        16\n",
      "       I-trt       0.94      0.97      0.95        31\n",
      "       I-vtp       1.00      1.00      1.00         1\n",
      "           O       0.98      0.99      0.99      1100\n",
      "\n",
      "    accuracy                           0.97      1635\n",
      "   macro avg       0.95      0.94      0.94      1635\n",
      "weighted avg       0.97      0.97      0.97      1635\n",
      "\n",
      "Slot F1-Score: 0.9518\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Start your MLflow run\n",
    "mlflow.transformers.autolog(disable=True)\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        'EPOCHS': EPOCHS,\n",
    "        'LEARNING_RATE': LEARNING_RATE,\n",
    "        'MAX_GRAD_NORM': MAX_GRAD_NORM,\n",
    "        'FREAZING_LAYERS': FREAZING_LAYERS,\n",
    "        'NUM_ADDITIONAL_LAYERS_TOP': NUM_ADDITIONAL_LAYERS_TOP,\n",
    "        'ACTIVATION': ACTIVATION\n",
    "    })\n",
    "    model, initial_loss = initialize_model(label2id=label2id, id2label=id2label, training_set=training_set,\n",
    "                                           freeze_layers=FREAZING_LAYERS, num_additional_layers=NUM_ADDITIONAL_LAYERS_TOP)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        model, epoch_loss, tr_accuracy = train(optimizer, MAX_GRAD_NORM, training_loader, model)\n",
    "        if i == EPOCHS - 1:\n",
    "            mlflow.log_metric(f'loss_epoch{i+1}', epoch_loss)\n",
    "            mlflow.log_metric(f'accuracy_epoch{i+1}', tr_accuracy)\n",
    "        print(\"tr_accuracy = \", tr_accuracy)\n",
    "        labels, predictions, eval_loss, eval_accuracy = valid(model, testing_loader, device, id2label, label2id)\n",
    "        print(\"eval_accuracy = \", eval_accuracy)\n",
    "\n",
    "    labels, predictions, eval_loss, eval_accuracy = valid(model, testing_loader, device, id2label, label2id)\n",
    "    mlflow.log_metric('eval_loss', eval_loss)\n",
    "    mlflow.log_metric('eval_accuracy', eval_accuracy)\n",
    "    mlflow.pytorch.log_model(model, 'model')\n",
    "    print(\"eval_accuracy = \", eval_accuracy)\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(labels, predictions, output_dict=True)\n",
    "\n",
    "    # Calculate the weighted average F1-score excluding 'O'\n",
    "    exlude = ['O', 'macro avg', 'accuracy', 'weighted avg']\n",
    "    total_support = sum(report[label]['support'] for label in report if label not in ['O', 'accuracy'])\n",
    "    weighted_f1_score = sum(report[label]['f1-score'] * report[label]['support'] for label in report if label not in ['O', 'accuracy']) / total_support\n",
    "    mlflow.log_metric('Slot avg F1-Score', weighted_f1_score)\n",
    "    mlflow.log_metric('macro avg F1-Score', report['macro avg']['f1-score'])\n",
    "    for label in report:\n",
    "        if label == 'accuracy':\n",
    "            break\n",
    "        mlflow.log_metric(f\"f1-score label {label}\", report[label]['f1-score'])\n",
    "    print(classification_report(labels, predictions))\n",
    "    print(f\"Slot F1-Score: {weighted_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c9928bb-6a78-4606-aeb0-5d31656845ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c9928bb-6a78-4606-aeb0-5d31656845ff",
    "outputId": "c6eaec55-4dbb-4ddb-e017-8aed5e9681b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-Level Predictions with Top 5 Labels:\n",
      "Word: میتونی\n",
      "  Label: O, Score: 12.4839\n",
      "  Label: B-cnd, Score: 3.0922\n",
      "  Label: B-loc, Score: 2.4632\n",
      "  Label: B-trt, Score: 1.0438\n",
      "  Label: I-apt, Score: 0.8055\n",
      "\n",
      "Word: برام\n",
      "  Label: O, Score: 12.7292\n",
      "  Label: B-cnd, Score: 3.1873\n",
      "  Label: B-loc, Score: 2.6843\n",
      "  Label: B-trt, Score: 1.0688\n",
      "  Label: I-apt, Score: 0.8031\n",
      "\n",
      "Word: یک\n",
      "  Label: O, Score: 12.6431\n",
      "  Label: B-cnd, Score: 3.0606\n",
      "  Label: B-loc, Score: 2.5046\n",
      "  Label: B-trt, Score: 1.0578\n",
      "  Label: I-apt, Score: 0.8356\n",
      "\n",
      "Word: دکتر\n",
      "  Label: O, Score: 12.4559\n",
      "  Label: B-cnd, Score: 3.2479\n",
      "  Label: B-loc, Score: 2.5353\n",
      "  Label: B-trt, Score: 1.1074\n",
      "  Label: B-srt, Score: 0.5578\n",
      "\n",
      "Word: اقای\n",
      "  Label: B-gnd, Score: 6.3486\n",
      "  Label: I-trt, Score: 3.5339\n",
      "  Label: B-vtp, Score: 3.4481\n",
      "  Label: B-trt, Score: 2.8411\n",
      "  Label: I-srt, Score: 2.6453\n",
      "\n",
      "Word: مامایی\n",
      "  Label: B-spy, Score: 8.0290\n",
      "  Label: B-srt, Score: 3.8382\n",
      "  Label: B-cnd, Score: 3.2573\n",
      "  Label: I-cnd, Score: 2.9115\n",
      "  Label: I-spy, Score: 2.3877\n",
      "\n",
      "Word: برای\n",
      "  Label: O, Score: 12.6928\n",
      "  Label: B-cnd, Score: 3.1929\n",
      "  Label: B-loc, Score: 2.6345\n",
      "  Label: B-trt, Score: 1.1272\n",
      "  Label: I-apt, Score: 0.7089\n",
      "\n",
      "Word: زایمان\n",
      "  Label: B-cnd, Score: 7.7416\n",
      "  Label: I-cnd, Score: 6.1437\n",
      "  Label: B-spy, Score: 4.7907\n",
      "  Label: B-apt, Score: 1.3434\n",
      "  Label: I-spy, Score: 1.1893\n",
      "\n",
      "Word: طبیعی\n",
      "  Label: I-cnd, Score: 4.9207\n",
      "  Label: I-spy, Score: 4.1755\n",
      "  Label: B-inc, Score: 3.6718\n",
      "  Label: B-gnd, Score: 2.5577\n",
      "  Label: I-inc, Score: 1.9477\n",
      "\n",
      "Word: زنم\n",
      "  Label: B-cnd, Score: 5.4820\n",
      "  Label: I-cnd, Score: 4.3671\n",
      "  Label: B-apt, Score: 4.3257\n",
      "  Label: O, Score: 3.3764\n",
      "  Label: B-loc, Score: 2.6788\n",
      "\n",
      "Word: در\n",
      "  Label: O, Score: 12.9786\n",
      "  Label: B-cnd, Score: 3.1906\n",
      "  Label: B-loc, Score: 3.0149\n",
      "  Label: B-trt, Score: 1.1789\n",
      "  Label: I-apt, Score: 0.8950\n",
      "\n",
      "Word: خیام\n",
      "  Label: O, Score: 11.9912\n",
      "  Label: B-loc, Score: 6.5955\n",
      "  Label: B-cnd, Score: 3.9529\n",
      "  Label: B-trt, Score: 1.8275\n",
      "  Label: B-apt, Score: 1.6312\n",
      "\n",
      "Word: مشهد\n",
      "  Label: B-loc, Score: 9.7951\n",
      "  Label: I-loc, Score: 5.7632\n",
      "  Label: O, Score: 3.5278\n",
      "  Label: B-apt, Score: 2.7884\n",
      "  Label: B-cnd, Score: 1.7924\n",
      "\n",
      "Word: معرفی\n",
      "  Label: O, Score: 12.4021\n",
      "  Label: B-cnd, Score: 2.8876\n",
      "  Label: B-loc, Score: 2.4458\n",
      "  Label: B-trt, Score: 0.9992\n",
      "  Label: I-apt, Score: 0.8312\n",
      "\n",
      "Word: کنی\n",
      "  Label: O, Score: 12.2225\n",
      "  Label: B-cnd, Score: 2.8112\n",
      "  Label: B-loc, Score: 2.2964\n",
      "  Label: B-trt, Score: 0.9040\n",
      "  Label: I-apt, Score: 0.8383\n",
      "\n",
      "Word: که\n",
      "  Label: O, Score: 12.4422\n",
      "  Label: B-cnd, Score: 2.8771\n",
      "  Label: B-loc, Score: 2.4131\n",
      "  Label: B-trt, Score: 1.0321\n",
      "  Label: I-apt, Score: 0.8584\n",
      "\n",
      "Word: قیمت\n",
      "  Label: B-trt, Score: 7.0222\n",
      "  Label: B-apt, Score: 3.2958\n",
      "  Label: B-cnd, Score: 2.9920\n",
      "  Label: B-loc, Score: 2.0771\n",
      "  Label: I-trt, Score: 1.9902\n",
      "\n",
      "Word: ویزیت\n",
      "  Label: I-trt, Score: 6.0328\n",
      "  Label: B-vtp, Score: 4.2317\n",
      "  Label: B-inc, Score: 2.9717\n",
      "  Label: B-gnd, Score: 2.3627\n",
      "  Label: I-inc, Score: 1.9682\n",
      "\n",
      "Word: مناسب\n",
      "  Label: I-trt, Score: 7.1770\n",
      "  Label: B-vtp, Score: 4.2476\n",
      "  Label: B-gnd, Score: 2.9842\n",
      "  Label: B-inc, Score: 2.8893\n",
      "  Label: B-trt, Score: 2.0227\n",
      "\n",
      "Word: داشته\n",
      "  Label: O, Score: 12.7207\n",
      "  Label: B-cnd, Score: 2.9923\n",
      "  Label: B-loc, Score: 2.5059\n",
      "  Label: B-trt, Score: 1.3583\n",
      "  Label: I-apt, Score: 0.9476\n",
      "\n",
      "Word: باشه\n",
      "  Label: O, Score: 12.5561\n",
      "  Label: B-cnd, Score: 2.9235\n",
      "  Label: B-loc, Score: 2.4657\n",
      "  Label: B-trt, Score: 1.0592\n",
      "  Label: I-apt, Score: 0.9304\n",
      "\n",
      "Word: و\n",
      "  Label: O, Score: 12.5737\n",
      "  Label: B-cnd, Score: 2.9553\n",
      "  Label: B-loc, Score: 2.4733\n",
      "  Label: B-trt, Score: 1.0939\n",
      "  Label: I-apt, Score: 0.9050\n",
      "\n",
      "Word: رازدار\n",
      "  Label: B-trt, Score: 7.9840\n",
      "  Label: I-trt, Score: 3.7209\n",
      "  Label: B-gnd, Score: 2.9784\n",
      "  Label: B-apt, Score: 2.6077\n",
      "  Label: B-vtp, Score: 1.4689\n",
      "\n",
      "Word: باشه\n",
      "  Label: O, Score: 12.6219\n",
      "  Label: B-cnd, Score: 2.9389\n",
      "  Label: B-loc, Score: 2.4719\n",
      "  Label: B-trt, Score: 1.1025\n",
      "  Label: I-apt, Score: 0.9437\n",
      "\n",
      "Word: و\n",
      "  Label: O, Score: 12.4995\n",
      "  Label: B-cnd, Score: 2.9428\n",
      "  Label: B-loc, Score: 2.3959\n",
      "  Label: B-trt, Score: 1.0021\n",
      "  Label: I-apt, Score: 0.8748\n",
      "\n",
      "Word: کمتر\n",
      "  Label: O, Score: 12.9898\n",
      "  Label: B-cnd, Score: 3.3922\n",
      "  Label: B-loc, Score: 2.8148\n",
      "  Label: B-trt, Score: 1.3674\n",
      "  Label: I-apt, Score: 0.9082\n",
      "\n",
      "Word: از\n",
      "  Label: O, Score: 12.5998\n",
      "  Label: B-cnd, Score: 2.9943\n",
      "  Label: B-loc, Score: 2.6373\n",
      "  Label: B-trt, Score: 1.1197\n",
      "  Label: I-apt, Score: 0.9941\n",
      "\n",
      "Word: ۳۵\n",
      "  Label: O, Score: 11.8558\n",
      "  Label: B-cnd, Score: 3.8635\n",
      "  Label: B-loc, Score: 2.9983\n",
      "  Label: B-apt, Score: 1.8561\n",
      "  Label: B-trt, Score: 1.7432\n",
      "\n",
      "Word: دقیقه\n",
      "  Label: O, Score: 12.1941\n",
      "  Label: B-cnd, Score: 2.8711\n",
      "  Label: B-loc, Score: 2.2759\n",
      "  Label: I-apt, Score: 1.4046\n",
      "  Label: B-trt, Score: 1.1301\n",
      "\n",
      "Word: معطل\n",
      "  Label: O, Score: 12.6970\n",
      "  Label: B-cnd, Score: 3.1663\n",
      "  Label: B-loc, Score: 2.6263\n",
      "  Label: B-trt, Score: 1.3133\n",
      "  Label: I-apt, Score: 0.8393\n",
      "\n",
      "Word: بشم\n",
      "  Label: O, Score: 12.4830\n",
      "  Label: B-cnd, Score: 3.0074\n",
      "  Label: B-loc, Score: 2.3658\n",
      "  Label: B-trt, Score: 0.9565\n",
      "  Label: I-apt, Score: 0.8294\n",
      "\n",
      "Word: ؟\n",
      "  Label: O, Score: 12.4554\n",
      "  Label: B-cnd, Score: 3.0168\n",
      "  Label: B-loc, Score: 2.4454\n",
      "  Label: B-trt, Score: 1.0323\n",
      "  Label: I-apt, Score: 0.8289\n",
      "\n",
      "Word: برای\n",
      "  Label: O, Score: 12.7680\n",
      "  Label: B-cnd, Score: 3.2174\n",
      "  Label: B-loc, Score: 2.8149\n",
      "  Label: B-trt, Score: 1.1606\n",
      "  Label: I-apt, Score: 0.9504\n",
      "\n",
      "Word: بعد\n",
      "  Label: O, Score: 12.7624\n",
      "  Label: B-cnd, Score: 3.9158\n",
      "  Label: B-loc, Score: 3.0176\n",
      "  Label: B-trt, Score: 1.3730\n",
      "  Label: B-apt, Score: 1.3231\n",
      "\n",
      "Word: ۲۰\n",
      "  Label: B-apt, Score: 6.9449\n",
      "  Label: I-apt, Score: 3.2679\n",
      "  Label: I-cnd, Score: 2.3923\n",
      "  Label: B-trt, Score: 2.0778\n",
      "  Label: B-loc, Score: 1.8860\n",
      "\n",
      "Word: شهریور\n",
      "  Label: I-apt, Score: 6.5938\n",
      "  Label: B-inc, Score: 4.2430\n",
      "  Label: I-inc, Score: 2.9824\n",
      "  Label: B-apt, Score: 2.9798\n",
      "  Label: I-loc, Score: 2.9344\n",
      "\n",
      "Word: و\n",
      "  Label: O, Score: 12.0698\n",
      "  Label: B-cnd, Score: 2.6998\n",
      "  Label: B-loc, Score: 2.2783\n",
      "  Label: B-trt, Score: 0.9571\n",
      "  Label: I-apt, Score: 0.9233\n",
      "\n",
      "Word: بیمه\n",
      "  Label: O, Score: 12.4536\n",
      "  Label: B-cnd, Score: 2.9636\n",
      "  Label: B-loc, Score: 2.5607\n",
      "  Label: B-trt, Score: 1.1462\n",
      "  Label: I-apt, Score: 0.8659\n",
      "\n",
      "Word: درمان\n",
      "  Label: B-inc, Score: 5.9442\n",
      "  Label: I-inc, Score: 4.5403\n",
      "  Label: B-vtp, Score: 2.9735\n",
      "  Label: I-apt, Score: 2.5101\n",
      "  Label: I-spy, Score: 2.4644\n",
      "\n",
      "Word: تکمیلی\n",
      "  Label: B-inc, Score: 5.6813\n",
      "  Label: I-inc, Score: 5.1451\n",
      "  Label: B-vtp, Score: 3.3628\n",
      "  Label: I-vtp, Score: 2.7484\n",
      "  Label: I-apt, Score: 2.5668\n",
      "\n",
      "Word: هستم\n",
      "  Label: O, Score: 12.4753\n",
      "  Label: B-cnd, Score: 2.8473\n",
      "  Label: B-loc, Score: 2.3887\n",
      "  Label: B-trt, Score: 1.0198\n",
      "  Label: I-apt, Score: 0.9435\n",
      "\n",
      "Word: .\n",
      "  Label: O, Score: 11.3940\n",
      "  Label: B-cnd, Score: 2.6496\n",
      "  Label: B-loc, Score: 1.7870\n",
      "  Label: I-apt, Score: 0.8660\n",
      "  Label: B-trt, Score: 0.8378\n",
      "\n",
      "میتونی (O) برام (O) یک (O) دکتر (O) اقای (B-gnd) مامایی (B-spy) برای (O) زایمان (B-cnd) طبیعی (I-cnd) زنم (B-cnd) در (O) خیام (O) مشهد (B-loc) معرفی (O) کنی (O) که (O) قیمت (B-trt) ویزیت (I-trt) مناسب (I-trt) داشته (O) باشه (O) و (O) رازدار (B-trt) باشه (O) و (O) کمتر (O) از (O) ۳۵ (O) دقیقه (O) معطل (O) بشم (O) ؟ (O) برای (O) بعد (O) ۲۰ (B-apt) شهریور (I-apt) و (O) بیمه (O) درمان (B-inc) تکمیلی (B-inc) هستم (O) . (O)\n"
     ]
    }
   ],
   "source": [
    "sentence = \"میتونی برام یک دکتر آقای مامایی برای زایمان طبیعی زنم در خیام مشهد معرفی کنی که قیمت ویزیت مناسب داشته باشه و رازدار باشه و کمتر از ۳۵ دقیقه معطل بشم ؟ برای بعد ۲۰ شهریور و بیمه درمان تکمیلی هستم .\"\n",
    "str_rep = predict(sentence, model, tokenizer, id2label, device, True)\n",
    "print(str_rep, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baea87e-ff8c-499a-9a0d-755a2efbe548",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3baea87e-ff8c-499a-9a0d-755a2efbe548",
    "outputId": "ee402ee4-8d3a-4e94-f114-f18c12678f5b"
   },
   "outputs": [],
   "source": [
    "sentence = \"برای گوش درد پسرم به یک متخصص شنوایی سنجی اصفهانی هستم که ویزیت غیر حضوری داشته باشه و اولین نوبت آن در ۲۵ مرداد باشد و بیمه دی هستم .\"\n",
    "str_rep = predict(sentence, model, tokenizer, id2label, device, True)\n",
    "print(str_rep, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NHMb-6sTFkJo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHMb-6sTFkJo",
    "outputId": "3ac7d183-ab1f-449c-828e-e7bdca7b8380"
   },
   "outputs": [],
   "source": [
    "if ANALYSIS:\n",
    "    for i, d in test_dataset.iterrows():\n",
    "        str_rep = predict(d['sentence'], model, tokenizer, id2label, device)\n",
    "        print(str_rep, sep=\"\\n\")\n",
    "        print(d['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oI_M2s_NG9S5",
   "metadata": {
    "id": "oI_M2s_NG9S5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
