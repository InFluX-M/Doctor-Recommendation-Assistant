{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7d521e-c6c0-4979-b855-b2d1f367a091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /home/user/anaconda3/envs/nlu/lib/python3.12/site-packages (4.44.2)\n",
      "Requirement already satisfied: pandas in /home/user/anaconda3/envs/nlu/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /home/user/anaconda3/envs/nlu/lib/python3.12/site-packages (1.26.4)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install transformers seqeval[gpu] pandas numpy sklearn mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46785b6",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4731ac97-9958-4832-a36e-85f1d7028d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForTokenClassification, PreTrainedTokenizer, PreTrainedModel\n",
    "import mlflow\n",
    "from seqeval.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a09b1f3-696a-49ca-999e-14d6d2f8121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2231f1",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "399d12cb-e530-4686-93c7-4d99d06e2bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>یک دکتر مرد خوب برای ارتوپد در کرمانشاه سراغ د...</td>\n",
       "      <td>O,O,B-gen,O,O,O,O,B-cit,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>آیا می توانید یک دکتر برای آسم معرفی کنید ؟</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کسی یک دکتر مرد برای افسردگی در خرم آباد یا مش...</td>\n",
       "      <td>O,O,O,B-gen,O,O,O,B-cit,I-cit,O,B-cit,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>آیا می توانید یک دکتر برای روانپزشکی معرفی کنید ؟</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>آیا می توانید یک دکتر برای زنان معرفی کنید ؟</td>\n",
       "      <td>O,O,O,O,O,O,B-gen,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  یک دکتر مرد خوب برای ارتوپد در کرمانشاه سراغ د...   \n",
       "1        آیا می توانید یک دکتر برای آسم معرفی کنید ؟   \n",
       "2  کسی یک دکتر مرد برای افسردگی در خرم آباد یا مش...   \n",
       "3  آیا می توانید یک دکتر برای روانپزشکی معرفی کنید ؟   \n",
       "4       آیا می توانید یک دکتر برای زنان معرفی کنید ؟   \n",
       "\n",
       "                                         label  \n",
       "0                O,O,B-gen,O,O,O,O,B-cit,O,O,O  \n",
       "1                          O,O,O,O,O,O,O,O,O,O  \n",
       "2  O,O,O,B-gen,O,O,O,B-cit,I-cit,O,B-cit,O,O,O  \n",
       "3                          O,O,O,O,O,O,O,O,O,O  \n",
       "4                      O,O,O,O,O,O,B-gen,O,O,O  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/labeled_doctor_req_chatgpt.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14b01165-6ace-4509-a11e-9fa923b9e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    'O': 0,\n",
    "    'B-gen': 1,\n",
    "    'I-gen': 2,\n",
    "    'B-cit': 3,\n",
    "    'I-cit': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1460dde-3480-4687-81a3-adeafd8a7cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: 'O',\n",
    "    1: 'B-gen',\n",
    "    2: 'I-gen',\n",
    "    3: 'B-cit',\n",
    "    4: 'I-cit'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b55ae5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سلام یک دکتر فوق تخصص زنان خانوم تو اصفهان سمت...</td>\n",
       "      <td>O,O,O,B-srt,I-srt,B-spy,B-gnd,O,B-cty,O,B-nhd,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سلام . یک متخصص مو داخل قم سمت پارک ملی برام پ...</td>\n",
       "      <td>O,O,O,B-srt,B-spy,O,B-cty,O,B-nhd,I-nhd,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>سلام . یک تخصص پوست و مو مرد درون قم سمت پارک ...</td>\n",
       "      <td>O,O,O,B-srt,B-spy,O,B-spy,B-gnd,O,B-cty,O,B-nh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سلام ، یک متخصص تغذیه شهر علویجه معرفی کن با ت...</td>\n",
       "      <td>O,O,O,B-srt,B-spy,O,B-cty,O,O,O,B-inc,I-inc,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سلام ، یک متخصص تغذیه مرد شهر گراش معرفی کن بر...</td>\n",
       "      <td>O,O,O,B-srt,B-spy,B-gnd,O,B-cty,O,O,O,O,B-cnd,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  سلام یک دکتر فوق تخصص زنان خانوم تو اصفهان سمت...   \n",
       "1  سلام . یک متخصص مو داخل قم سمت پارک ملی برام پ...   \n",
       "2  سلام . یک تخصص پوست و مو مرد درون قم سمت پارک ...   \n",
       "3  سلام ، یک متخصص تغذیه شهر علویجه معرفی کن با ت...   \n",
       "4  سلام ، یک متخصص تغذیه مرد شهر گراش معرفی کن بر...   \n",
       "\n",
       "                                               label  \n",
       "0  O,O,O,B-srt,I-srt,B-spy,B-gnd,O,B-cty,O,B-nhd,...  \n",
       "1  O,O,O,B-srt,B-spy,O,B-cty,O,B-nhd,I-nhd,O,O,O,...  \n",
       "2  O,O,O,B-srt,B-spy,O,B-spy,B-gnd,O,B-cty,O,B-nh...  \n",
       "3  O,O,O,B-srt,B-spy,O,B-cty,O,O,O,B-inc,I-inc,O,...  \n",
       "4  O,O,O,B-srt,B-spy,B-gnd,O,B-cty,O,O,O,O,B-cnd,...  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/form_data.csv\", index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "19e24494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-apt',\n",
       " 'B-cnd',\n",
       " 'B-cty',\n",
       " 'B-gnd',\n",
       " 'B-inc',\n",
       " 'B-nhd',\n",
       " 'B-spy',\n",
       " 'B-srt',\n",
       " 'B-trt',\n",
       " 'B-vtp',\n",
       " 'B-wtt',\n",
       " 'I-apt',\n",
       " 'I-cnd',\n",
       " 'I-inc',\n",
       " 'I-nhd',\n",
       " 'I-spy',\n",
       " 'I-srt',\n",
       " 'I-trt',\n",
       " 'I-vtp',\n",
       " 'I-wtt',\n",
       " 'O']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all unique BIO tags used in the dataset\n",
    "unique_bio_tags = set(tag for bio_tag in data['label'] for tag in bio_tag.split(','))\n",
    "\n",
    "# Convert to a sorted list\n",
    "unique_bio_tags_list = sorted(unique_bio_tags)\n",
    "\n",
    "unique_bio_tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f1934ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    'O': 0,\n",
    "    'B-apt': 1,\n",
    "    'I-apt': 2,\n",
    "    'B-cty': 3,\n",
    "    'I-cty': 4,\n",
    "    'B-cnd': 5,\n",
    "    'I-cnd': 6,\n",
    "    'B-gnd': 7,\n",
    "    'I-gnd': 8,\n",
    "    'B-inc': 9,\n",
    "    'I-inc': 10,\n",
    "    'B-nhd': 11,\n",
    "    'I-nhd': 12,\n",
    "    'B-srt': 13,\n",
    "    'I-srt': 14,\n",
    "    'B-spy': 15,\n",
    "    'I-spy': 16,\n",
    "    'B-trt': 17,\n",
    "    'I-trt': 18,\n",
    "    'B-vtp': 19,\n",
    "    'I-vtp': 20,\n",
    "    'B-wtt': 21,\n",
    "    'I-wtt': 22\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ada7e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['sentence', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0d7bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['label'].apply(lambda x: x.replace(\" \", \",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bbc397",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49a951c1-e578-4f20-8f43-067e775762e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/nlu/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "tokenizer = BertTokenizer.from_pretrained('HooshvareLab/bert-fa-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dee005",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40d77460-803e-4539-a840-70c1026e6ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence: str, text_labels: str, tokenizer: PreTrainedTokenizer) -> tuple[list[str], list[str]]:\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75bbdf06-635f-48b9-8d6a-84bc06cad836",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, tokenizer: PreTrainedTokenizer, max_len: int) -> None:\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index :int):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.sentence[index]  \n",
    "        word_labels = self.data.label[index]  \n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "        \n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "        \n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        \n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d19af0c",
   "metadata": {},
   "source": [
    "## Split into Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2bf055f2-291b-40b4-8e61-06fb051f8602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (93, 2)\n",
      "TRAIN Dataset: (74, 2)\n",
      "TEST Dataset: (19, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb59597c-76a1-4b72-a1ff-599655c27da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([    2,  4285,  1012,  4642,  4283,  9084,  4124,  1379,  2799,  4246,\n",
       "          4124,  1379,  4197,  7811, 17953,  2800, 38905,  3404,  9747,  8444,\n",
       "          2840,  3803, 14114,  1012,  6599, 12139,  1379,  3757, 16172,  4435,\n",
       "         12139,  1012,  5072,  5505,  2820, 41774,  2008,  1379,  8512,  8113,\n",
       "          5442,  2820,  3151, 12139,  1012,  4202,  2820,  5671, 14114,  1012,\n",
       "          3130,  2791,  2829,  3551, 23537, 75915,  1012,     4,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'targets': tensor([ 0,  0,  0,  0,  0, 13, 17,  0, 17, 18,  0,  0, 17, 18,  0,  0,  0,  0,\n",
       "          5,  6,  0,  0,  0,  0,  3,  0,  0,  0, 11, 12,  0,  0,  1,  0,  0,  0,\n",
       "          0,  0,  0,  0, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0, 21, 22, 22, 22,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35e9f58b-549e-41cf-8019-a32cef969cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]       O\n",
      "سلام        O\n",
      ".           O\n",
      "یه          O\n",
      "دکتر        O\n",
      "تخصص        B-srt\n",
      "خوب         B-trt\n",
      "و           O\n",
      "با          B-trt\n",
      "تجربه       I-trt\n",
      "خوب         O\n",
      "و           O\n",
      "خوش         B-trt\n",
      "اخلاق       I-trt\n",
      "میخوام      O\n",
      "که          O\n",
      "بتونه       O\n",
      "مشکل        O\n",
      "ناراحتی     B-cnd\n",
      "معده        I-cnd\n",
      "رو          O\n",
      "حل          O\n",
      "کنه         O\n",
      ".           O\n",
      "شیراز       B-cty\n",
      "باشه        O\n",
      "و           O\n",
      "سمت         O\n",
      "باهنر       B-nhd\n",
      "جنوبی       I-nhd\n"
     ]
    }
   ],
   "source": [
    "# print the first 30 tokens and corresponding labels\n",
    "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"ids\"][:30]), training_set[0][\"targets\"][:30]):\n",
    "  print('{0:10}  {1}'.format(token, id2label[label.item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61c58c8e-6486-4128-90fc-1fa884dbb37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9684ef",
   "metadata": {},
   "source": [
    "# Define and track models with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b1c5a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "FREAZING_LAYERS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ec69a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file 'mlflow/mlruns/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/nlu/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py\", line 317, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/envs/nlu/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py\", line 410, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/envs/nlu/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py\", line 1341, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/envs/nlu/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py\", line 1334, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/anaconda3/envs/nlu/lib/python3.12/site-packages/mlflow/utils/file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'mlflow/mlruns/meta.yaml' does not exist.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/user/Desktop/hammasir-project/mlflow/968568366775758109', creation_time=1724758511411, experiment_id='968568366775758109', last_update_time=1724758511411, lifecycle_stage='active', name='NER', tags={}>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"mlflow\")\n",
    "mlflow.set_experiment(\"NER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169509bb",
   "metadata": {},
   "source": [
    "## Writing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9eb312b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(id2label: dict, label2id: dict, training_set: dataset, freeze_layers: int = 0) -> tuple[PreTrainedModel, torch.Tensor]:\n",
    "    model = BertForTokenClassification.from_pretrained(\n",
    "        'HooshvareLab/bert-fa-base-uncased', \n",
    "        num_labels=len(id2label),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "    \n",
    "    # Freeze the first `freeze_layers` transformer layers\n",
    "    for param in model.bert.embeddings.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for i in range(freeze_layers):\n",
    "        for param in model.bert.encoder.layer[i].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    model.to(device)\n",
    "    ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "    mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "    targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "    ids = ids.to(device)\n",
    "    mask = mask.to(device)\n",
    "    targets = targets.to(device)\n",
    "    outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "    initial_loss = outputs[0]\n",
    "    return model, initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4bd72ebb-5449-4f67-bb07-c24423b5fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(optimizer: torch.optim.Adam, max_norm: int, training_loader: DataLoader, model: PreTrainedModel) -> tuple[PreTrainedModel, float, float]:\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "        \n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=max_norm\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    return model, epoch_loss, tr_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "432c9934-d6d3-453e-a6b9-2152d9cf1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model: PreTrainedModel, testing_loader: DataLoader, device: str, id2label: dict, label2id: dict) -> tuple[list[str], list[str], float, float]:\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "\n",
    "    return labels, predictions, eval_loss, eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c0027504-f122-4884-a07e-1191ff34ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence: str, model: PreTrainedModel, tokenizer: BertTokenizer, id2label: dict, device: str) -> tuple[str, list[str]]:\n",
    "  inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "  # move to gpu\n",
    "  ids = inputs[\"input_ids\"].to(device)\n",
    "  mask = inputs[\"attention_mask\"].to(device)\n",
    "  # forward pass\n",
    "  outputs = model(ids, mask)\n",
    "  logits = outputs[0]\n",
    "\n",
    "  active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "  flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "  tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "  token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "  wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "  word_level_predictions = []\n",
    "  for pair in wp_preds:\n",
    "    if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
    "      # skip prediction\n",
    "      continue\n",
    "    else:\n",
    "      word_level_predictions.append(pair[1])\n",
    "\n",
    "  # we join tokens, if they are not special ones\n",
    "  str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
    "  return str_rep, word_level_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c97b8b",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a0eb3366-f0e4-416e-a972-29de1c5fbdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 3.233670473098755\n",
      "tr_accuracy =  0.5419695997049545\n",
      "Training loss per 100 training steps: 0.5881020426750183\n",
      "tr_accuracy =  0.6372003120162022\n",
      "Training loss per 100 training steps: 0.4729653000831604\n",
      "tr_accuracy =  0.6412305876920411\n",
      "Training loss per 100 training steps: 0.36786866188049316\n",
      "tr_accuracy =  0.6469864243189588\n",
      "Training loss per 100 training steps: 0.433521032333374\n",
      "tr_accuracy =  0.6468173681283788\n",
      "Training loss per 100 training steps: 0.29667139053344727\n",
      "tr_accuracy =  0.6721701555047517\n",
      "Training loss per 100 training steps: 0.22286473214626312\n",
      "tr_accuracy =  0.7125645737720623\n",
      "Training loss per 100 training steps: 0.16869600117206573\n",
      "tr_accuracy =  0.7478057272825701\n",
      "Training loss per 100 training steps: 0.16590897738933563\n",
      "tr_accuracy =  0.7900252634324513\n",
      "Training loss per 100 training steps: 0.1696079671382904\n",
      "tr_accuracy =  0.8121903545889342\n",
      "Training loss per 100 training steps: 0.14075171947479248\n",
      "tr_accuracy =  0.8437476583428385\n",
      "Training loss per 100 training steps: 0.11901021003723145\n",
      "tr_accuracy =  0.8715325881399374\n",
      "Training loss per 100 training steps: 0.09686321765184402\n",
      "tr_accuracy =  0.8877574361501768\n",
      "Training loss per 100 training steps: 0.19390732049942017\n",
      "tr_accuracy =  0.8957564725755194\n",
      "Training loss per 100 training steps: 0.1294611394405365\n",
      "tr_accuracy =  0.9209399835615957\n",
      "Training loss per 100 training steps: 0.05737616866827011\n",
      "tr_accuracy =  0.9215866541913461\n",
      "Training loss per 100 training steps: 0.07577855885028839\n",
      "tr_accuracy =  0.924065120046866\n",
      "Training loss per 100 training steps: 0.0798928439617157\n",
      "tr_accuracy =  0.9371124292951422\n",
      "Training loss per 100 training steps: 0.045196015387773514\n",
      "tr_accuracy =  0.941674206060075\n",
      "Training loss per 100 training steps: 0.045405734330415726\n",
      "tr_accuracy =  0.9470876912676339\n",
      "Training loss per 100 training steps: 0.05989818647503853\n",
      "tr_accuracy =  0.9551447678473188\n",
      "Training loss per 100 training steps: 0.051285725086927414\n",
      "tr_accuracy =  0.9604226859212206\n",
      "Training loss per 100 training steps: 0.039105162024497986\n",
      "tr_accuracy =  0.9670625647857128\n",
      "Training loss per 100 training steps: 0.023412950336933136\n",
      "tr_accuracy =  0.9665169646545752\n",
      "Training loss per 100 training steps: 0.039119038730859756\n",
      "tr_accuracy =  0.9718613956763203\n",
      "Validation loss per 100 evaluation steps: 0.05068124458193779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 17:16:09 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpmbq4qri9/model/data, flavor: pytorch). Fall back to return ['torch==2.4.0', 'cloudpickle==3.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/08/31 17:16:10 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_accuracy =  0.9259790317038761\n"
     ]
    }
   ],
   "source": [
    "mlflow.transformers.autolog(disable=True)\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        'EPOCHS': EPOCHS,\n",
    "        'LEARNING_RATE': LEARNING_RATE,\n",
    "        'MAX_GRAD_NORM': MAX_GRAD_NORM,\n",
    "        'FREAZING_LAYERS': FREAZING_LAYERS\n",
    "    })\n",
    "    model, initial_loss = initialize_model(label2id=label2id, id2label=id2label, training_set=training_set, freeze_layers=FREAZING_LAYERS)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    for i in range(EPOCHS):\n",
    "        model, epoch_loss, tr_accuracy = train(optimizer, MAX_GRAD_NORM, training_loader, model)\n",
    "        mlflow.log_metric(f'loss_epoch{i+1}', epoch_loss)\n",
    "        mlflow.log_metric(f'accuracy_epoch{i+1}', tr_accuracy)\n",
    "        print(\"tr_accuracy = \", tr_accuracy)    \n",
    "        \n",
    "    labels, predictions, eval_loss, eval_accuracy = valid(model, testing_loader, device, id2label, label2id)\n",
    "    mlflow.log_metric('eval_loss', eval_loss)\n",
    "    mlflow.log_metric('eval_accuracy', eval_accuracy)\n",
    "    precision = precision_score([labels], [predictions], average=None)\n",
    "    recall = recall_score([labels], [predictions], average=None)\n",
    "    mlflow.log_metric('cit_precision', precision[0])\n",
    "    mlflow.log_metric('cit_recall', recall[0])\n",
    "    mlflow.log_metric('gen_precision', precision[1])\n",
    "    mlflow.log_metric('gen_recall', recall[1])\n",
    "    mlflow.pytorch.log_model(model, 'model')\n",
    "    print(\"eval_accuracy = \", eval_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0c9928bb-6a78-4606-aeb0-5d31656845ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "سلام یک دکتر دکترای حرفهای تغذیه خانم تو تهران سمت معالی اباد میخوام که تجربه کافی داشته باشه و برای پس فردا بهم نوبت بده و با نیروهای مسلح قرارداد داشته باشه و تایم انتظار توی مطب کمتر از نیم ساعت باشه .\n",
      "['O', 'O', 'O', 'B-srt', 'B-spy', 'B-spy', 'B-gnd', 'O', 'B-cty', 'O', 'B-nhd', 'B-nhd', 'I-nhd', 'O', 'O', 'B-trt', 'I-trt', 'O', 'O', 'O', 'O', 'B-apt', 'B-apt', 'O', 'O', 'O', 'O', 'O', 'B-inc', 'I-inc', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-wtt', 'I-wtt', 'I-wtt', 'I-wtt', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"سلام یک دکتر دکترای حرفه‌ای تغذیه خانم تو تهران سمت معالی آباد میخوام که تجربه کافی داشته باشه و برای پس فردا بهم نوبت بده و با نیرو های مسلح قرارداد داشته باشه و تایم انتظار توی مطب کمتر از نیم ساعت باشه.\"\n",
    "sentence_out, word_level_predictions = predict(sentence, model, tokenizer, id2label, device)\n",
    "print(sentence_out, word_level_predictions, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baea87e-ff8c-499a-9a0d-755a2efbe548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed15ddd-50d6-408a-aa32-fb32991dc6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d7092d-398e-4c85-a3b5-2f7aa43737f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
